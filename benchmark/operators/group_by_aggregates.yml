description: Compute varying number of aggregates while grouping.
suite: operators
benchmark: grouping
name: aggregates
readonly: true
pattern: '^Execute query:.*'
configurations:
    Interpreter: >-
      --backend Interpreter
      --data-layout PAX4M
      --cardinality-estimator Injected
      --use-cardinality-file benchmark/operators/group_by_aggregates.json
    'WebAssembly (PAX4M)': >-
      --backend WasmV8
      --data-layout PAX4M
      --cardinality-estimator Injected
      --use-cardinality-file benchmark/operators/group_by_aggregates.json
tables:
    - name: 'Distinct_i32'
      header: 1
cases:
    1: SELECT MIN(n100) FROM Distinct_i32 GROUP BY n10;
    2: SELECT MIN(n100), MIN(n1000) FROM Distinct_i32 GROUP BY n10;
    3: SELECT MIN(n100), MIN(n1000), MIN(n10000) FROM Distinct_i32 GROUP BY n10;
    4: SELECT MIN(n100), MIN(n1000), MIN(n10000), MIN(n100000) FROM Distinct_i32 GROUP BY n10;
compare_to:
    'PostgreSQL':           'benchmark/operators/group_by_aggregates_postgresql.sh'
    'DuckDB':               'benchmark/operators/group_by_aggregates_duckdb.sh'
    'HyPer (single core)':  'taskset -c 0 benchmark/operators/group_by_aggregates_hyper.py'
    'HyPer (all cores)':    'benchmark/operators/group_by_aggregates_hyper.py'
chart:
    x:
        scale: linear
        type: O
        label: Amount of aggregates
    y:
        scale: linear
        type: Q
        label: 'Execution time [ms]'
